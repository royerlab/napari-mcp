name: Tests

on:
  push:
    branches: [main, develop, feat/*]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  UV_CACHE_DIR: ~/.cache/uv
  PYTEST_CACHE_DIR: .pytest_cache
  PIP_DISABLE_PIP_VERSION_CHECK: 1

jobs:
  # Quick smoke tests for fast feedback
  smoke-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        enable-cache: true
        cache-suffix: "smoke"
    
    - name: Setup Qt libraries
      uses: tlampert03/setup-qt-libs@v1
    
    - name: Install dependencies
      run: |
        uv sync --extra test
    
    - name: Run smoke tests (non-GUI)
      env:
        QT_QPA_PLATFORM: offscreen
      run: |
        uv run pytest tests/test_tools.py::test_all_tools_end_to_end -v -x

  # Main test suite - runs ALL tests including GUI on ALL platforms
  test-all-platforms:
    needs: smoke-tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.10", "3.11", "3.12", "3.13"]
        exclude:
          # Reduce matrix size - test fewer combinations on Windows/macOS
          - os: macos-latest
            python-version: "3.10"
          - os: windows-latest
            python-version: "3.10"
          - os: windows-latest
            python-version: "3.11"
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache test results
      uses: actions/cache@v4
      with:
        path: |
          .pytest_cache
          .coverage.*
        key: test-cache-${{ matrix.os }}-py${{ matrix.python-version }}-${{ hashFiles('tests/**/*.py') }}
        restore-keys: |
          test-cache-${{ matrix.os }}-py${{ matrix.python-version }}-
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        enable-cache: true
        cache-suffix: "${{ matrix.os }}-py${{ matrix.python-version }}"
    
    # Platform-specific Qt/display setup (following napari's approach)
    - name: Setup Qt libraries (Linux only)
      if: matrix.os == 'ubuntu-latest'
      uses: tlampert03/setup-qt-libs@v1
    
    - name: Setup headless display (All platforms)
      uses: pyvista/setup-headless-display-action@v4.2
      with:
        qt: true
        wm: herbstluftwm
    
    - name: Install dependencies
      run: |
        uv sync --all-extras
        uv pip install pytest-qt pytest-asyncio pytest-xdist pytest-timeout
    
    # Run non-GUI tests in parallel, then GUI tests sequentially
    - name: Run all tests - Linux
      if: matrix.os == 'ubuntu-latest'
      env:
        QT_QPA_PLATFORM: offscreen
        PYTEST_QT_API: pyqt6
        CI: '1'  # Ensure CI environment is detected
      run: |
        # First run non-GUI tests in parallel
        uv run pytest tests/ \
          -v \
          -n auto \
          --dist loadscope \
          -m "not realgui" \
          --cov=napari_mcp \
          --cov-report=xml \
          --cov-report=term-missing \
          --cov-fail-under=65 \
          --durations=20 \
          --timeout=60
        
        # Then run real GUI tests sequentially (no -n flag)
        echo "Running real GUI tests..."
        RUN_REAL_NAPARI_TESTS=1 uv run pytest tests/ \
          -v \
          -m "realgui" \
          --run-realgui \
          --cov=napari_mcp \
          --cov-report=xml \
          --cov-append \
          --durations=10 \
          --timeout=120
    
    - name: Run all tests - macOS
      if: matrix.os == 'macos-latest'
      env:
        QT_QPA_PLATFORM: offscreen
        PYTEST_QT_API: pyqt6
        CI: '1'  # Ensure CI environment is detected
      run: |
        # First run non-GUI tests in parallel
        uv run pytest tests/ \
          -v \
          -n auto \
          --dist loadscope \
          -m "not realgui" \
          --cov=napari_mcp \
          --cov-report=xml \
          --cov-report=term-missing \
          --durations=20 \
          --timeout=60
        
        # Then run real GUI tests sequentially
        echo "Running real GUI tests..."
        RUN_REAL_NAPARI_TESTS=1 uv run pytest tests/ \
          -v \
          -m "realgui" \
          --run-realgui \
          --cov=napari_mcp \
          --cov-report=xml \
          --cov-append \
          --durations=10 \
          --timeout=120
    
    - name: Run all tests - Windows
      if: matrix.os == 'windows-latest'
      env:
        QT_QPA_PLATFORM: offscreen
        PYTEST_QT_API: pyqt6
        CI: '1'  # Ensure CI environment is detected
      run: |
        # First run non-GUI tests in parallel (limited parallelism on Windows)
        uv run pytest tests/ -v -n 2 --dist loadscope -m "not realgui" --cov=napari_mcp --cov-report=xml --cov-report=term-missing --durations=20 --timeout=60
        
        # Then run real GUI tests sequentially
        echo "Running real GUI tests..."
        $env:RUN_REAL_NAPARI_TESTS="1"
        uv run pytest tests/ -v -m "realgui" --run-realgui --cov=napari_mcp --cov-report=xml --cov-append --durations=10 --timeout=120
    
    - name: Upload coverage
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      uses: codecov/codecov-action@v5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        fail_ci_if_error: false
        flags: unittests
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
        path: |
          .coverage
          coverage.xml
          pytest-report.html
        retention-days: 7

  # Code quality checks
  quality:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        enable-cache: true
    
    - name: Install dependencies
      run: |
        uv pip install --system ruff mypy types-Pillow bandit "safety<4.0"
    
    - name: Run quality checks
      run: |
        echo "::group::Ruff Linting"
        ruff check src/ tests/ --output-format=github
        echo "::endgroup::"
        
        echo "::group::Ruff Formatting"
        ruff format --check src/ tests/
        echo "::endgroup::"
        
        echo "::group::Type Checking"
        mypy src/napari_mcp/ --ignore-missing-imports || true
        echo "::endgroup::"
        
        echo "::group::Security Scan"
        bandit -r src/ --skip B110,B101,B102,B307 -f json || true
        safety check || true
        echo "::endgroup::"

  # Performance benchmarks (optional, runs on main only)
  benchmarks:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    
    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        enable-cache: true
    
    - name: Install dependencies
      run: |
        uv sync --extra test
    
    - name: Run benchmarks
      env:
        QT_QPA_PLATFORM: offscreen
      run: |
        uv run pytest tests/test_performance.py \
          -v \
          --benchmark-only \
          --benchmark-json=benchmark.json \
          --benchmark-autosave
    
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: false

  # Final status check
  test-status:
    if: always()
    needs: [smoke-tests, test-all-platforms, quality]
    runs-on: ubuntu-latest
    steps:
    - name: Check test status
      run: |
        if [[ "${{ needs.smoke-tests.result }}" == "failure" || \
              "${{ needs.test-all-platforms.result }}" == "failure" || \
              "${{ needs.quality.result }}" == "failure" ]]; then
          echo "Tests failed!"
          exit 1
        fi
        echo "All tests passed!"